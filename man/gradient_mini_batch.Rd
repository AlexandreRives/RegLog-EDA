% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gradient_function.R
\name{gradient_mini_batch}
\alias{gradient_mini_batch}
\title{Mini_batch gradient descent}
\usage{
gradient_mini_batch(
  df,
  var_X,
  var_y,
  nb_batch,
  learning_rate,
  max_iter,
  graph,
  epsilon
)
}
\arguments{
\item{df}{dataset}

\item{var_X}{names of the X columns}

\item{var_y}{names of the Y columns}

\item{nb_batch}{batch size}

\item{learning_rate}{the learning rate}

\item{max_iter}{number of iterations}

\item{graph}{TRUE if you want to plot the cost list while the gradient descent is running.}

\item{epsilon}{Tolerance's threshold of the cost list convergence.}
}
\value{
list of theta and the cost list
}
\description{
Mini_batch gradient descent computes the gradient using a batch size of the dataset
}
\author{
Frintz Elisa, NDiaye Deffa, Rives Alexandre
}
